defaults:
  - model: deepspeech2
  - metrics: inference_metrics
  - datasets: inference
  - dataloader: default
  - transforms: inference
  - _self_
text_encoder:
  _target_: src.text_encoder.CTCTextEncoder
  lm_path: 3-gram.pruned.3e-7.arpa
  unigrams_path: librispeech-vocab.txt
inferencer:
  device_tensors: [ "spectrogram", "text_encoded" ] # which tensors should be on device (ex. GPU)
  device: auto # device name or "auto"
  save_path: "inference" # any name here, can be a dataset name
  seed: 42
  from_pretrained: "checkpoint-epoch200.pth" # path to the pretrained model